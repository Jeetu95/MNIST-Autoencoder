{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder generating MNIST Data.\n",
    "This notebook demonstrates the generation of autoencoder data on MNIST datasets.\n",
    "<br>\n",
    "We are going to use two data sets here. To know more about the datasets vist the links given :- \n",
    "  - MNIST Handwritten Digits - [link](http://yann.lecun.com/exdb/mnist/)\n",
    "  - MNIST Fashion            - [link](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "We are only using Neural Network based architecture here. In future work I tend to implement a CovNet based architecture. In this notebook we are also going to discuss the activations in the bottleneck layer.<br><br>\n",
    "##### This is the basic structure of the architecture used here.\n",
    "![autoencoder architecture](images/autoencoder.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version - 1.12.0\n",
      "Keras Version - 2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "# Since I am using a dark backgroud. Comment it out if you are using a light theme\n",
    "plt.style.use(['dark_background'])\n",
    "\n",
    "# tensorboard --logdir=logs/ --host localhost --port 8088\n",
    "print(f'Tensorflow Version - {tf.__version__}')\n",
    "print(f'Keras Version - {keras.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some project oriented values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'digit'\n",
    "MODEL_NAME = f'FCCN_{DATASET}_autoencoder'\n",
    "MODEL_CHECKPOINT_PATH = f'saved_models/checkpoint/{MODEL_NAME}_epoch-'\n",
    "MODEL_PATH = f'saved_models/{MODEL_NAME}.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of the model used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(saved = True):\n",
    "    \"\"\"This method returns the autoencoder model and the encoder model.\n",
    "    Returns a saved model if MODEL_NAME is found.\n",
    "    Fully Connected Neural Network Autoencoder Architecture (FCCN Autoencoder)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    saved - Get the saved model from the MODEL_PATH if exists.(default True)\n",
    "    \n",
    "    Returns:\n",
    "    autoencoder_model - Uncompiled Keras model for autoencoder network\n",
    "    encoder_model     - Uncompiled Keras model for encoder network for \n",
    "                        future activation map visualization.\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    if os.path.isfile(MODEL_PATH) and saved:\n",
    "        print(\"Loading saved model {}\".format(MODEL_NAME))\n",
    "        autoencoder_model = load_model(MODEL_PATH)\n",
    "        \n",
    "        input_layer = Input(shape=(784,),name='input_layer')\n",
    "        output_layer = input_layer\n",
    "        layers_list = autoencoder_model.layers\n",
    "\n",
    "        index  = 1\n",
    "        while True:\n",
    "            #print(f'Layer Index {index}')\n",
    "            layer = layers_list[index]\n",
    "            output_layer = layer (output_layer)\n",
    "            index +=1\n",
    "            if layer.name == 'bottleneck_layer':\n",
    "                break\n",
    "        encoder_model = Model(input_layer,output_layer)\n",
    "        \n",
    "        return autoencoder_model,encoder_model\n",
    "    \n",
    "    \n",
    "    dropout_rate = 0.13\n",
    "    input_layer = Input(shape=(784,),name='input_layer')\n",
    "    layer = Dense(512,name='encode_1',activation='relu')(input_layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    layer = Dense(256,name='encode_2',activation='relu')(layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    layer = Dense(128,name='encode_3',activation='relu')(layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    layer = Dense(64,name='encode_4',activation='relu')(layer)\n",
    "    \n",
    "    bottleneck_layer = Dense(36,name='bottleneck_layer',activation='relu')(layer)\n",
    "    \n",
    "    layer = Dense(64,name='decode_1',activation='relu')(bottleneck_layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    layer = Dense(128,name='decode_2',activation='relu')(layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    layer = Dense(256,name='decode_3',activation='relu')(layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    layer = Dense(512,name='decode_4',activation='relu')(layer)\n",
    "    layer = Dropout(dropout_rate)(layer)\n",
    "    output_layer = Dense(784,name='output_layer',activation='sigmoid')(layer)\n",
    "    \n",
    "    \n",
    "    autoencoder_model = Model(input_layer,output_layer)\n",
    "    encoder_model = Model(input_layer,bottleneck_layer)\n",
    "    return autoencoder_model,encoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST Digit Dataset\n",
      "Training Data Shape : (60000, 784)\n",
      "Testing Data Shape  : (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "def process_data(data_type = 'digit'):\n",
    "    \"\"\"This method returns the train and test data.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    data_type - Name of the dataset used.(default 'digit')\n",
    "                'digit' - MNIST Digits Dataset\n",
    "                'fashion' - MNIST Fashion Dataset\n",
    "    \n",
    "    Returns:\n",
    "    train,test - The training and testing data for respective datasets.\n",
    "    \"\"\"\n",
    "    train,test = None, None\n",
    "    if data_type == 'digit':\n",
    "        print('Loading MNIST Digit Dataset')\n",
    "        (train,_),(test,_) = mnist.load_data()\n",
    "    elif data_type == 'fashion' :\n",
    "        print('Loading MNIST Fashion Dataset')\n",
    "        (train,_),(test,_) = fashion_mnist.load_data()\n",
    "    train = train/255\n",
    "    test = test/255\n",
    "    train = train.reshape((len(train), np.prod(train.shape[1:])))\n",
    "    test = test.reshape((len(test), np.prod(test.shape[1:])))\n",
    "    print(f'Training Data Shape : {train.shape}')\n",
    "    print(f'Testing Data Shape  : {test.shape}')\n",
    "    return train,test\n",
    "\n",
    "X_train, X_test = process_data(data_type=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(original,activation,created):\n",
    "    \"\"\"This method plots the original image,activation map of the bottleneck layer\n",
    "    and reconstructed image.\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    original   - Numpy array of the original data (shape = (784,))\n",
    "    activation - Numpy array of the activation map data (shape = (36,))\n",
    "    created    -  Numpy array of the reconstructed data (shape = (784,))\n",
    "    \n",
    "    \"\"\"\n",
    "    shape = int(np.sqrt(original.shape[0]))\n",
    "    map_shape = int(np.sqrt(activation.shape[0]))\n",
    "    \n",
    "    original = np.reshape(original,(shape,shape))\n",
    "    activation = np.reshape(activation,(map_shape,map_shape))\n",
    "    created = np.reshape(created,(shape,shape))\n",
    "    \n",
    "    plt.figure(figsize=(14,10))\n",
    "    \n",
    "    gs = gridspec.GridSpec(4, 8)\n",
    "    gs.update(wspace=0.5)\n",
    "    ax1 = plt.subplot(gs[:2, :4], )\n",
    "    ax2 = plt.subplot(gs[:2, 4:])\n",
    "    ax3 = plt.subplot(gs[2:, 2:6])\n",
    "    \n",
    "    ax1.set_title(\"Original Image\\n\",fontdict = {'fontsize':16})\n",
    "    ax1.imshow(original,cmap = 'gray')\n",
    "    ax1.set_axis_off()\n",
    "    \n",
    "    ax2.set_title(\"Re-Constructed Image\\n\",fontdict = {'fontsize':16})\n",
    "    ax2.imshow(created,cmap = 'gray')\n",
    "    ax2.set_axis_off()\n",
    "    \n",
    "    ax3.set_title(\"\\nActivation Map of\\n Bottleneck Layer\",fontdict = {'fontsize':16})\n",
    "    ax3.imshow(activation,cmap = 'gray')\n",
    "    ax3.set_axis_off()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_result():\n",
    "    \"\"\"This method picks up a random datapoint from testing data and plots the result image.\n",
    "    Result image consists of Orginal Image, Re-Constructed Image and \n",
    "    Activation Map of Bottleneck Layer\"\"\"\n",
    "    rand_idx = np.random.randint(0,len(X_test))\n",
    "    plot_result(X_test[rand_idx],activation_map[rand_idx],autoencoder_prediction[rand_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model FCCN_digit_autoencoder\n",
      "Structure of Autoencoder Model\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encode_1 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "encode_2 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "encode_3 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "encode_4 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "bottleneck_layer (Dense)     (None, 36)                2340      \n",
      "_________________________________________________________________\n",
      "decode_1 (Dense)             (None, 64)                2368      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "decode_2 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "decode_3 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "decode_4 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 1,154,228\n",
      "Trainable params: 1,154,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder,encoder = get_models()\n",
    "print('Structure of Autoencoder Model\\n')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure of Encoder Model\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encode_1 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "encode_2 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "encode_3 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "encode_4 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "bottleneck_layer (Dense)     (None, 36)                2340      \n",
      "=================================================================\n",
      "Total params: 576,740\n",
      "Trainable params: 576,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Structure of Encoder Model\\n')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Hyperparametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer (Adam Optimizer)\n",
    "adam = Adam(lr=LR)\n",
    "\n",
    "# Making of missing directories.\n",
    "if os.path.isdir('saved_models/') == False:\n",
    "    os.makedirs('saved_models/')\n",
    "if os.path.isdir('saved_models/checkpoint/') == False:\n",
    "    os.makedirs('saved_models/checkpoint/')\n",
    "\n",
    "# Declaring all the callbacks required.\n",
    "tensoboard = TensorBoard(log_dir='logs\\{}'.format(time()),batch_size=BATCH_SIZE,update_freq='epoch')\n",
    "save_model = ModelCheckpoint(filepath=MODEL_CHECKPOINT_PATH+'{epoch}.h5',monitor='loss')\n",
    "early_stop = EarlyStopping(monitor='loss',patience=3,verbose=1,restore_best_weights=True)\n",
    "\n",
    "callbacks = [tensoboard,save_model,early_stop]\n",
    "\n",
    "# Model Compilation\n",
    "autoencoder.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = autoencoder.fit(X_train,X_train,batch_size=BATCH_SIZE,\n",
    "                       epochs=EPOCHS,verbose=2,callbacks=callbacks)\n",
    "autoencoder.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_prediction = autoencoder.predict(X_test)\n",
    "activation_map = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For MNIST Handwritten Digits\n",
    "random_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Verdict\n",
    "These graphs are form Tensorboard.\n",
    "<br>\n",
    "\n",
    " ### MNIST Handwritten Digits\n",
    "   - Final Loss - 0.1338\n",
    "     ![](images\\loss-digit.png)\n",
    "<br>\n",
    "   - Final Accuracy - 0.8069\n",
    "     ![](images\\acc-digit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
